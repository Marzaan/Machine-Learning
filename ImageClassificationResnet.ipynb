{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting pixel mean improves accuracy\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "depth = n * 6 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, depth, num_classes=10):\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0)\n",
    "    \n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape=input_shape, depth=depth)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'ResNet'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 689s 441ms/step - loss: 1.5577 - accuracy: 0.4957 - val_loss: 1.3175 - val_accuracy: 0.5885\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raiya\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 663s 424ms/step - loss: 1.1732 - accuracy: 0.6413 - val_loss: 1.2601 - val_accuracy: 0.6216\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 671s 429ms/step - loss: 1.0148 - accuracy: 0.7013 - val_loss: 1.0874 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 664s 425ms/step - loss: 0.9275 - accuracy: 0.7355 - val_loss: 1.1463 - val_accuracy: 0.6708\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 659s 421ms/step - loss: 0.8659 - accuracy: 0.7572 - val_loss: 0.9603 - val_accuracy: 0.7298\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 660s 422ms/step - loss: 0.8216 - accuracy: 0.7751 - val_loss: 1.0897 - val_accuracy: 0.7083\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 665s 425ms/step - loss: 0.7919 - accuracy: 0.7874 - val_loss: 1.1992 - val_accuracy: 0.6876\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 761s 487ms/step - loss: 0.7577 - accuracy: 0.8002 - val_loss: 0.8240 - val_accuracy: 0.7861\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 860s 550ms/step - loss: 0.7330 - accuracy: 0.8126 - val_loss: 0.8537 - val_accuracy: 0.7794\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 746s 477ms/step - loss: 0.7149 - accuracy: 0.8184 - val_loss: 1.2981 - val_accuracy: 0.6828\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 779s 498ms/step - loss: 0.7009 - accuracy: 0.8234 - val_loss: 1.1360 - val_accuracy: 0.7081\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 664s 425ms/step - loss: 0.6849 - accuracy: 0.8293 - val_loss: 0.9874 - val_accuracy: 0.7534\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 660s 422ms/step - loss: 0.6697 - accuracy: 0.8355 - val_loss: 0.8135 - val_accuracy: 0.7920\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 677s 433ms/step - loss: 0.6535 - accuracy: 0.8412 - val_loss: 0.8271 - val_accuracy: 0.7894\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 740s 474ms/step - loss: 0.6473 - accuracy: 0.8446 - val_loss: 0.8269 - val_accuracy: 0.7940\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 736s 471ms/step - loss: 0.6408 - accuracy: 0.8468 - val_loss: 0.8034 - val_accuracy: 0.7999\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 662s 424ms/step - loss: 0.6280 - accuracy: 0.8518 - val_loss: 0.8783 - val_accuracy: 0.7788\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 724s 463ms/step - loss: 0.6203 - accuracy: 0.8542 - val_loss: 0.7353 - val_accuracy: 0.8237\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 664s 425ms/step - loss: 0.6173 - accuracy: 0.8574 - val_loss: 0.7914 - val_accuracy: 0.8118\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 659s 422ms/step - loss: 0.6071 - accuracy: 0.8596 - val_loss: 0.7889 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d53c77b948>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"weights-ResNetImageClassificationAug.hdf5\"\n",
    "model.save_weights(fname,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model.save('project_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"weights-ResNetImageClassificationAug.hdf5\"\n",
    "model.load_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model = load_model('project_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 51s 5ms/step\n",
      "Test loss: 0.7889395555496216\n",
      "Test accuracy: 0.801800012588501\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_image1 =image.load_img('Image/automobile1.jpg',target_size =(32,32,3))\n",
    "test_image =image.img_to_array(test_image1) \n",
    "test_image =np.expand_dims(test_image, axis =0) \n",
    "result = model.predict(test_image)\n",
    "plt.imshow(test_image1)\n",
    "\n",
    "print(result) \n",
    "if result[0][0]==1: \n",
    "    print(\"Aeroplane\") \n",
    "elif result[0][1]==1: \n",
    "    print('Automobile') \n",
    "elif result[0][2]==1: \n",
    "    print('Bird') \n",
    "elif result[0][3]==1: \n",
    "    print('Cat') \n",
    "elif result[0][4]==1: \n",
    "    print('Deer') \n",
    "elif result[0][5]==1: \n",
    "    print('Dog') \n",
    "elif result[0][6]==1: \n",
    "    print('Frog') \n",
    "elif result[0][7]==1: \n",
    "    print('Horse') \n",
    "elif result[0][8]==1: \n",
    "    print('Ship') \n",
    "elif result[0][9]==1: \n",
    "    print('Truck') \n",
    "else:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely class : automobile , Probability :  1.0\n",
      "Most second  likely class : truck , Probability :  0.0\n",
      "Most third  likely class : ship , Probability :  0.0\n"
     ]
    }
   ],
   "source": [
    "class_name =['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "index = np.argsort(result[0,:])\n",
    "print('Most likely class :', class_name[index[9]] , ', Probability : ', result[0 , index[9]])\n",
    "print('Most second  likely class :', class_name[index[8]] , ', Probability : ', result[0 , index[8]])\n",
    "print('Most third  likely class :', class_name[index[7]] , ', Probability : ', result[0 , index[7]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
