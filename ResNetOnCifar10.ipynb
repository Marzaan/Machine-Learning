{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport numpy as np\nimport os","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training parameters\nbatch_size = 32\nepochs = 200\nnum_classes = 10","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input image dimensions.\ninput_shape = x_train.shape[1:]\ninput_shape","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(32, 32, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize data.\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subtracting pixel mean improves accuracy\nx_train_mean = np.mean(x_train, axis=0)\nx_train -= x_train_mean\nx_test -= x_train_mean","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)","execution_count":18,"outputs":[{"output_type":"stream","text":"x_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\ny_train shape: (50000, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert class vectors to binary class matrices.\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    return lr","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 3\ndepth = n * 6 + 2","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnet(input_shape, depth, num_classes=10):\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.,\n    zoom_range=0.,\n    channel_shift_range=0.,\n    fill_mode='nearest',\n    cval=0.,\n    horizontal_flip=True,\n    vertical_flip=False,\n    rescale=None,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.0)\n    \ndatagen.fit(x_train)","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = resnet(input_shape=input_shape, depth=depth)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=lr_schedule(0)),\n              metrics=['accuracy'])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":27,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n                                                                 batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n                                                                 batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n                                                                 batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n                                                                 batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n                                                                 batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n                                                                 batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n                                                                 batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n                                                                 batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n==================================================================================================\nTotal params: 274,442\nTrainable params: 273,066\nNon-trainable params: 1,376\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'ResNet'\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"h=model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                    validation_data=(x_test, y_test),\n                    epochs=epochs, verbose=1, workers=4,\n                    callbacks=callbacks)","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.6903 - accuracy: 0.8253 - val_loss: 0.9550 - val_accuracy: 0.7558\nEpoch 2/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.6783 - accuracy: 0.8302 - val_loss: 0.9319 - val_accuracy: 0.7552\nEpoch 3/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.6586 - accuracy: 0.8372 - val_loss: 0.8667 - val_accuracy: 0.7786\nEpoch 4/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.6497 - accuracy: 0.8406 - val_loss: 0.8737 - val_accuracy: 0.7788\nEpoch 5/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.6388 - accuracy: 0.8448 - val_loss: 0.7559 - val_accuracy: 0.8108\nEpoch 6/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.6377 - accuracy: 0.8468 - val_loss: 0.8977 - val_accuracy: 0.7722\nEpoch 7/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.6268 - accuracy: 0.8501 - val_loss: 0.9877 - val_accuracy: 0.7528\nEpoch 8/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.6186 - accuracy: 0.8557 - val_loss: 0.8941 - val_accuracy: 0.7724\nEpoch 9/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.6096 - accuracy: 0.8572 - val_loss: 0.7608 - val_accuracy: 0.8137\nEpoch 10/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.6051 - accuracy: 0.8596 - val_loss: 0.7395 - val_accuracy: 0.8232\nEpoch 11/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.6030 - accuracy: 0.8609 - val_loss: 0.8090 - val_accuracy: 0.8113\nEpoch 12/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.5972 - accuracy: 0.8633 - val_loss: 0.7383 - val_accuracy: 0.8199\nEpoch 13/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.5881 - accuracy: 0.8660 - val_loss: 0.7974 - val_accuracy: 0.8068\nEpoch 14/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5854 - accuracy: 0.8668 - val_loss: 0.7628 - val_accuracy: 0.8181\nEpoch 15/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5814 - accuracy: 0.8689 - val_loss: 0.7642 - val_accuracy: 0.8177\nEpoch 16/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.5772 - accuracy: 0.8700 - val_loss: 0.7967 - val_accuracy: 0.8091\nEpoch 17/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.5747 - accuracy: 0.8720 - val_loss: 0.7700 - val_accuracy: 0.8184\nEpoch 18/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5729 - accuracy: 0.8719 - val_loss: 0.9584 - val_accuracy: 0.7776\nEpoch 19/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5658 - accuracy: 0.8751 - val_loss: 0.8167 - val_accuracy: 0.8147\nEpoch 20/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5607 - accuracy: 0.8763 - val_loss: 0.7824 - val_accuracy: 0.8186\nEpoch 21/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.5637 - accuracy: 0.8743 - val_loss: 0.8193 - val_accuracy: 0.8050\nEpoch 22/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5529 - accuracy: 0.8789 - val_loss: 0.6845 - val_accuracy: 0.8377\nEpoch 23/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.5537 - accuracy: 0.8802 - val_loss: 0.6982 - val_accuracy: 0.8433\nEpoch 24/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.5559 - accuracy: 0.8777 - val_loss: 0.6969 - val_accuracy: 0.8398\nEpoch 25/200\n1563/1563 [==============================] - 76s 48ms/step - loss: 0.5483 - accuracy: 0.8810 - val_loss: 0.6932 - val_accuracy: 0.8383\nEpoch 26/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.5474 - accuracy: 0.8817 - val_loss: 0.6826 - val_accuracy: 0.8472\nEpoch 27/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5473 - accuracy: 0.8816 - val_loss: 0.6804 - val_accuracy: 0.8373\nEpoch 28/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5462 - accuracy: 0.8826 - val_loss: 0.7154 - val_accuracy: 0.8391\nEpoch 29/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5388 - accuracy: 0.8851 - val_loss: 0.6733 - val_accuracy: 0.8450\nEpoch 30/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5378 - accuracy: 0.8858 - val_loss: 0.6603 - val_accuracy: 0.8521\nEpoch 31/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.5392 - accuracy: 0.8844 - val_loss: 0.7601 - val_accuracy: 0.8187\nEpoch 32/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.5373 - accuracy: 0.8853 - val_loss: 0.6572 - val_accuracy: 0.8451\nEpoch 33/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.5357 - accuracy: 0.8878 - val_loss: 0.6070 - val_accuracy: 0.8685\nEpoch 34/200\n1563/1563 [==============================] - 76s 48ms/step - loss: 0.5341 - accuracy: 0.8869 - val_loss: 0.7263 - val_accuracy: 0.8363\nEpoch 35/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5266 - accuracy: 0.8881 - val_loss: 0.9952 - val_accuracy: 0.7848\nEpoch 36/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5322 - accuracy: 0.8885 - val_loss: 0.7292 - val_accuracy: 0.8337\nEpoch 37/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.5280 - accuracy: 0.8910 - val_loss: 0.6393 - val_accuracy: 0.8571\nEpoch 38/200\n1563/1563 [==============================] - 78s 50ms/step - loss: 0.5250 - accuracy: 0.8898 - val_loss: 0.8186 - val_accuracy: 0.8068\nEpoch 39/200\n1563/1563 [==============================] - 76s 49ms/step - loss: 0.5248 - accuracy: 0.8907 - val_loss: 0.8112 - val_accuracy: 0.8053\nEpoch 40/200\n1563/1563 [==============================] - 75s 48ms/step - loss: 0.5214 - accuracy: 0.8927 - val_loss: 0.6531 - val_accuracy: 0.8554\nEpoch 41/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.5205 - accuracy: 0.8917 - val_loss: 0.6519 - val_accuracy: 0.8546\nEpoch 42/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.5229 - accuracy: 0.8913 - val_loss: 0.7416 - val_accuracy: 0.8247\nEpoch 43/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.5213 - accuracy: 0.8909 - val_loss: 0.7508 - val_accuracy: 0.8300\nEpoch 44/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5157 - accuracy: 0.8952 - val_loss: 0.6977 - val_accuracy: 0.8364\nEpoch 45/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5140 - accuracy: 0.8942 - val_loss: 0.6837 - val_accuracy: 0.8485\nEpoch 46/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5164 - accuracy: 0.8947 - val_loss: 0.6597 - val_accuracy: 0.8495\nEpoch 47/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5168 - accuracy: 0.8938 - val_loss: 0.6552 - val_accuracy: 0.8571\nEpoch 48/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.5112 - accuracy: 0.8958 - val_loss: 0.7341 - val_accuracy: 0.8376\nEpoch 49/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5100 - accuracy: 0.8942 - val_loss: 0.7817 - val_accuracy: 0.8240\nEpoch 50/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5128 - accuracy: 0.8946 - val_loss: 0.7849 - val_accuracy: 0.8258\nEpoch 51/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5101 - accuracy: 0.8957 - val_loss: 0.6142 - val_accuracy: 0.8682\nEpoch 52/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5138 - accuracy: 0.8953 - val_loss: 0.7950 - val_accuracy: 0.8219\nEpoch 53/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5113 - accuracy: 0.8960 - val_loss: 0.7135 - val_accuracy: 0.8401\nEpoch 54/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.5053 - accuracy: 0.8962 - val_loss: 0.7337 - val_accuracy: 0.8350\nEpoch 55/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5112 - accuracy: 0.8958 - val_loss: 0.8014 - val_accuracy: 0.8181\nEpoch 56/200\n","name":"stdout"},{"output_type":"stream","text":"1563/1563 [==============================] - 69s 44ms/step - loss: 0.5061 - accuracy: 0.8979 - val_loss: 0.6684 - val_accuracy: 0.8509\nEpoch 57/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.5035 - accuracy: 0.8966 - val_loss: 0.7111 - val_accuracy: 0.8372\nEpoch 58/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.5027 - accuracy: 0.8987 - val_loss: 0.6028 - val_accuracy: 0.8701\nEpoch 59/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.5054 - accuracy: 0.8965 - val_loss: 0.7940 - val_accuracy: 0.8192\nEpoch 60/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.5020 - accuracy: 0.8980 - val_loss: 0.8809 - val_accuracy: 0.8041\nEpoch 61/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5018 - accuracy: 0.9008 - val_loss: 0.7085 - val_accuracy: 0.8413\nEpoch 62/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5006 - accuracy: 0.8993 - val_loss: 0.6992 - val_accuracy: 0.8423\nEpoch 63/200\n1563/1563 [==============================] - 70s 44ms/step - loss: 0.4980 - accuracy: 0.8997 - val_loss: 0.7073 - val_accuracy: 0.8410\nEpoch 64/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.5011 - accuracy: 0.8985 - val_loss: 0.8061 - val_accuracy: 0.8184\nEpoch 65/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4960 - accuracy: 0.8995 - val_loss: 0.7224 - val_accuracy: 0.8381\nEpoch 66/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4996 - accuracy: 0.9003 - val_loss: 0.6273 - val_accuracy: 0.8632\nEpoch 67/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4997 - accuracy: 0.8993 - val_loss: 0.8291 - val_accuracy: 0.8197\nEpoch 68/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4980 - accuracy: 0.8999 - val_loss: 0.6414 - val_accuracy: 0.8590\nEpoch 69/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4943 - accuracy: 0.9016 - val_loss: 0.6588 - val_accuracy: 0.8557\nEpoch 70/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4932 - accuracy: 0.9030 - val_loss: 0.7167 - val_accuracy: 0.8438\nEpoch 71/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4927 - accuracy: 0.9006 - val_loss: 0.6037 - val_accuracy: 0.8685\nEpoch 72/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4924 - accuracy: 0.9024 - val_loss: 0.6821 - val_accuracy: 0.8476\nEpoch 73/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4927 - accuracy: 0.9027 - val_loss: 0.6943 - val_accuracy: 0.8435\nEpoch 74/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4959 - accuracy: 0.9006 - val_loss: 0.6720 - val_accuracy: 0.8501\nEpoch 75/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4929 - accuracy: 0.9015 - val_loss: 0.6808 - val_accuracy: 0.8529\nEpoch 76/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4934 - accuracy: 0.9027 - val_loss: 0.6922 - val_accuracy: 0.8492\nEpoch 77/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4872 - accuracy: 0.9028 - val_loss: 0.6751 - val_accuracy: 0.8486\nEpoch 78/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4889 - accuracy: 0.9023 - val_loss: 0.6131 - val_accuracy: 0.8706\nEpoch 79/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4903 - accuracy: 0.9020 - val_loss: 0.6467 - val_accuracy: 0.8624\nEpoch 80/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4921 - accuracy: 0.9025 - val_loss: 0.7432 - val_accuracy: 0.8316\nEpoch 81/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4918 - accuracy: 0.9023 - val_loss: 0.7325 - val_accuracy: 0.8292\nEpoch 82/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4900 - accuracy: 0.9043 - val_loss: 0.6890 - val_accuracy: 0.8474\nEpoch 83/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4885 - accuracy: 0.9019 - val_loss: 0.6334 - val_accuracy: 0.8670\nEpoch 84/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4849 - accuracy: 0.9047 - val_loss: 0.7011 - val_accuracy: 0.8458\nEpoch 85/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4880 - accuracy: 0.9027 - val_loss: 0.7319 - val_accuracy: 0.8386\nEpoch 86/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4851 - accuracy: 0.9051 - val_loss: 0.6356 - val_accuracy: 0.8627\nEpoch 87/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4853 - accuracy: 0.9039 - val_loss: 0.6023 - val_accuracy: 0.8685\nEpoch 88/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4846 - accuracy: 0.9041 - val_loss: 0.6632 - val_accuracy: 0.8530\nEpoch 89/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4857 - accuracy: 0.9052 - val_loss: 0.6652 - val_accuracy: 0.8587\nEpoch 90/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4876 - accuracy: 0.9043 - val_loss: 0.6306 - val_accuracy: 0.8615\nEpoch 91/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4817 - accuracy: 0.9052 - val_loss: 0.6479 - val_accuracy: 0.8556\nEpoch 92/200\n1563/1563 [==============================] - 70s 44ms/step - loss: 0.4855 - accuracy: 0.9039 - val_loss: 0.6306 - val_accuracy: 0.8626\nEpoch 93/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4791 - accuracy: 0.9056 - val_loss: 0.6704 - val_accuracy: 0.8512\nEpoch 94/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4820 - accuracy: 0.9054 - val_loss: 0.6592 - val_accuracy: 0.8623\nEpoch 95/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4820 - accuracy: 0.9051 - val_loss: 0.6688 - val_accuracy: 0.8451\nEpoch 96/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4841 - accuracy: 0.9043 - val_loss: 0.6564 - val_accuracy: 0.8520\nEpoch 97/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4800 - accuracy: 0.9055 - val_loss: 0.6184 - val_accuracy: 0.8729\nEpoch 98/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4795 - accuracy: 0.9059 - val_loss: 0.6761 - val_accuracy: 0.8509\nEpoch 99/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4789 - accuracy: 0.9064 - val_loss: 0.6238 - val_accuracy: 0.8668\nEpoch 100/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4776 - accuracy: 0.9058 - val_loss: 0.6658 - val_accuracy: 0.8478\nEpoch 101/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4809 - accuracy: 0.9046 - val_loss: 0.7581 - val_accuracy: 0.8356\nEpoch 102/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4786 - accuracy: 0.9058 - val_loss: 0.6326 - val_accuracy: 0.8640\nEpoch 103/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4806 - accuracy: 0.9064 - val_loss: 0.6010 - val_accuracy: 0.8691\nEpoch 104/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4806 - accuracy: 0.9069 - val_loss: 0.6335 - val_accuracy: 0.8636\nEpoch 105/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4783 - accuracy: 0.9054 - val_loss: 0.6890 - val_accuracy: 0.8482\nEpoch 106/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4732 - accuracy: 0.9073 - val_loss: 0.6591 - val_accuracy: 0.8629\nEpoch 107/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4805 - accuracy: 0.9052 - val_loss: 0.7066 - val_accuracy: 0.8475\nEpoch 108/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4747 - accuracy: 0.9060 - val_loss: 0.6552 - val_accuracy: 0.8640\nEpoch 109/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4772 - accuracy: 0.9069 - val_loss: 0.6964 - val_accuracy: 0.8470\nEpoch 110/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4687 - accuracy: 0.9090 - val_loss: 0.7693 - val_accuracy: 0.8302\nEpoch 111/200\n","name":"stdout"},{"output_type":"stream","text":"1563/1563 [==============================] - 71s 46ms/step - loss: 0.4737 - accuracy: 0.9081 - val_loss: 0.8231 - val_accuracy: 0.8177\nEpoch 112/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4768 - accuracy: 0.9069 - val_loss: 0.7849 - val_accuracy: 0.8333\nEpoch 113/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4739 - accuracy: 0.9086 - val_loss: 0.7215 - val_accuracy: 0.8400\nEpoch 114/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4723 - accuracy: 0.9084 - val_loss: 0.6621 - val_accuracy: 0.8545\nEpoch 115/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4759 - accuracy: 0.9070 - val_loss: 0.6926 - val_accuracy: 0.8528\nEpoch 116/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4708 - accuracy: 0.9091 - val_loss: 0.7072 - val_accuracy: 0.8434\nEpoch 117/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4712 - accuracy: 0.9091 - val_loss: 0.6512 - val_accuracy: 0.8587\nEpoch 118/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4713 - accuracy: 0.9081 - val_loss: 0.6435 - val_accuracy: 0.8583\nEpoch 119/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4682 - accuracy: 0.9092 - val_loss: 0.6905 - val_accuracy: 0.8505\nEpoch 120/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4712 - accuracy: 0.9092 - val_loss: 0.6598 - val_accuracy: 0.8525\nEpoch 121/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4714 - accuracy: 0.9093 - val_loss: 0.6004 - val_accuracy: 0.8719\nEpoch 122/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4682 - accuracy: 0.9106 - val_loss: 0.7450 - val_accuracy: 0.8316\nEpoch 123/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4741 - accuracy: 0.9068 - val_loss: 0.6602 - val_accuracy: 0.8611\nEpoch 124/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4700 - accuracy: 0.9093 - val_loss: 0.7949 - val_accuracy: 0.8270\nEpoch 125/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4727 - accuracy: 0.9077 - val_loss: 0.6686 - val_accuracy: 0.8597\nEpoch 126/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4699 - accuracy: 0.9089 - val_loss: 0.6231 - val_accuracy: 0.8678\nEpoch 127/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4714 - accuracy: 0.9077 - val_loss: 0.5997 - val_accuracy: 0.8735\nEpoch 128/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4691 - accuracy: 0.9095 - val_loss: 0.6415 - val_accuracy: 0.8618\nEpoch 129/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4710 - accuracy: 0.9095 - val_loss: 0.6078 - val_accuracy: 0.8685\nEpoch 130/200\n1563/1563 [==============================] - 74s 48ms/step - loss: 0.4658 - accuracy: 0.9099 - val_loss: 0.6354 - val_accuracy: 0.8673\nEpoch 131/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.4666 - accuracy: 0.9105 - val_loss: 0.6480 - val_accuracy: 0.8605\nEpoch 132/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4672 - accuracy: 0.9094 - val_loss: 0.7854 - val_accuracy: 0.8251\nEpoch 133/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4645 - accuracy: 0.9103 - val_loss: 0.6424 - val_accuracy: 0.8584\nEpoch 134/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4668 - accuracy: 0.9104 - val_loss: 0.7321 - val_accuracy: 0.8392\nEpoch 135/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4649 - accuracy: 0.9102 - val_loss: 0.6322 - val_accuracy: 0.8610\nEpoch 136/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4638 - accuracy: 0.9105 - val_loss: 0.6035 - val_accuracy: 0.8715\nEpoch 137/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4640 - accuracy: 0.9099 - val_loss: 0.6174 - val_accuracy: 0.8734\nEpoch 138/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4704 - accuracy: 0.9093 - val_loss: 0.6841 - val_accuracy: 0.8523\nEpoch 139/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4656 - accuracy: 0.9103 - val_loss: 0.6053 - val_accuracy: 0.8667\nEpoch 140/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4645 - accuracy: 0.9095 - val_loss: 0.6903 - val_accuracy: 0.8503\nEpoch 141/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4668 - accuracy: 0.9097 - val_loss: 0.7015 - val_accuracy: 0.8503\nEpoch 142/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4615 - accuracy: 0.9114 - val_loss: 0.6043 - val_accuracy: 0.8651\nEpoch 143/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4636 - accuracy: 0.9111 - val_loss: 0.7661 - val_accuracy: 0.8348\nEpoch 144/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4646 - accuracy: 0.9106 - val_loss: 0.7033 - val_accuracy: 0.8440\nEpoch 145/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4685 - accuracy: 0.9099 - val_loss: 0.6165 - val_accuracy: 0.8654\nEpoch 146/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4644 - accuracy: 0.9092 - val_loss: 0.8420 - val_accuracy: 0.8135\nEpoch 147/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4616 - accuracy: 0.9111 - val_loss: 0.7115 - val_accuracy: 0.8484\nEpoch 148/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4656 - accuracy: 0.9098 - val_loss: 0.6250 - val_accuracy: 0.8655\nEpoch 149/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4636 - accuracy: 0.9117 - val_loss: 0.5871 - val_accuracy: 0.8764\nEpoch 150/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4651 - accuracy: 0.9098 - val_loss: 0.6033 - val_accuracy: 0.8666\nEpoch 151/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4634 - accuracy: 0.9120 - val_loss: 0.6089 - val_accuracy: 0.8703\nEpoch 152/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4618 - accuracy: 0.9107 - val_loss: 0.6352 - val_accuracy: 0.8636\nEpoch 153/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4607 - accuracy: 0.9106 - val_loss: 0.7027 - val_accuracy: 0.8365\nEpoch 154/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4625 - accuracy: 0.9117 - val_loss: 0.6326 - val_accuracy: 0.8632\nEpoch 155/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4588 - accuracy: 0.9126 - val_loss: 0.6298 - val_accuracy: 0.8716\nEpoch 156/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4601 - accuracy: 0.9120 - val_loss: 0.8388 - val_accuracy: 0.8217\nEpoch 157/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4641 - accuracy: 0.9088 - val_loss: 0.7115 - val_accuracy: 0.8438\nEpoch 158/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4603 - accuracy: 0.9113 - val_loss: 0.6942 - val_accuracy: 0.8550\nEpoch 159/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4575 - accuracy: 0.9121 - val_loss: 0.7264 - val_accuracy: 0.8419\nEpoch 160/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4581 - accuracy: 0.9127 - val_loss: 0.6104 - val_accuracy: 0.8714\nEpoch 161/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4635 - accuracy: 0.9108 - val_loss: 0.7035 - val_accuracy: 0.8416\nEpoch 162/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4600 - accuracy: 0.9112 - val_loss: 0.6712 - val_accuracy: 0.8505\nEpoch 163/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4585 - accuracy: 0.9110 - val_loss: 0.6813 - val_accuracy: 0.8528\nEpoch 164/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4585 - accuracy: 0.9120 - val_loss: 0.6412 - val_accuracy: 0.8621\nEpoch 165/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4550 - accuracy: 0.9132 - val_loss: 0.6420 - val_accuracy: 0.8598\nEpoch 166/200\n","name":"stdout"},{"output_type":"stream","text":"1563/1563 [==============================] - 71s 45ms/step - loss: 0.4587 - accuracy: 0.9119 - val_loss: 0.7721 - val_accuracy: 0.8393\nEpoch 167/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4610 - accuracy: 0.9112 - val_loss: 0.6859 - val_accuracy: 0.8531\nEpoch 168/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4579 - accuracy: 0.9119 - val_loss: 1.1833 - val_accuracy: 0.7569\nEpoch 169/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4581 - accuracy: 0.9111 - val_loss: 0.8936 - val_accuracy: 0.8076\nEpoch 170/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4522 - accuracy: 0.9135 - val_loss: 0.6821 - val_accuracy: 0.8532\nEpoch 171/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4577 - accuracy: 0.9127 - val_loss: 0.6205 - val_accuracy: 0.8669\nEpoch 172/200\n1563/1563 [==============================] - 69s 44ms/step - loss: 0.4566 - accuracy: 0.9127 - val_loss: 0.7219 - val_accuracy: 0.8502\nEpoch 173/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4557 - accuracy: 0.9116 - val_loss: 0.6225 - val_accuracy: 0.8702\nEpoch 174/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4538 - accuracy: 0.9133 - val_loss: 0.8121 - val_accuracy: 0.8197\nEpoch 175/200\n1563/1563 [==============================] - 70s 45ms/step - loss: 0.4573 - accuracy: 0.9135 - val_loss: 0.7312 - val_accuracy: 0.8453\nEpoch 176/200\n1563/1563 [==============================] - 78s 50ms/step - loss: 0.4571 - accuracy: 0.9110 - val_loss: 0.5834 - val_accuracy: 0.8733\nEpoch 177/200\n1563/1563 [==============================] - 74s 47ms/step - loss: 0.4561 - accuracy: 0.9133 - val_loss: 0.6526 - val_accuracy: 0.8609\nEpoch 178/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4578 - accuracy: 0.9123 - val_loss: 0.6315 - val_accuracy: 0.8634\nEpoch 179/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4532 - accuracy: 0.9142 - val_loss: 0.6037 - val_accuracy: 0.8724\nEpoch 180/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4548 - accuracy: 0.9131 - val_loss: 0.6507 - val_accuracy: 0.8636\nEpoch 181/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4531 - accuracy: 0.9127 - val_loss: 0.6235 - val_accuracy: 0.8666\nEpoch 182/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4280 - accuracy: 0.9217 - val_loss: 0.5674 - val_accuracy: 0.8847\nEpoch 183/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4241 - accuracy: 0.9233 - val_loss: 0.5590 - val_accuracy: 0.8869\nEpoch 184/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4204 - accuracy: 0.9259 - val_loss: 0.5580 - val_accuracy: 0.8873\nEpoch 185/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4172 - accuracy: 0.9277 - val_loss: 0.5526 - val_accuracy: 0.8879\nEpoch 186/200\n1563/1563 [==============================] - 73s 47ms/step - loss: 0.4172 - accuracy: 0.9266 - val_loss: 0.5529 - val_accuracy: 0.8885\nEpoch 187/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4154 - accuracy: 0.9276 - val_loss: 0.5483 - val_accuracy: 0.8899\nEpoch 188/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4123 - accuracy: 0.9277 - val_loss: 0.5466 - val_accuracy: 0.8906\nEpoch 189/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4094 - accuracy: 0.9286 - val_loss: 0.5481 - val_accuracy: 0.8894\nEpoch 190/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4090 - accuracy: 0.9284 - val_loss: 0.5464 - val_accuracy: 0.8901\nEpoch 191/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.4011 - accuracy: 0.9314 - val_loss: 0.5427 - val_accuracy: 0.8913\nEpoch 192/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4084 - accuracy: 0.9291 - val_loss: 0.5420 - val_accuracy: 0.8910\nEpoch 193/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.4040 - accuracy: 0.9320 - val_loss: 0.5388 - val_accuracy: 0.8926\nEpoch 194/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4055 - accuracy: 0.9310 - val_loss: 0.5381 - val_accuracy: 0.8928\nEpoch 195/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4032 - accuracy: 0.9307 - val_loss: 0.5384 - val_accuracy: 0.8930\nEpoch 196/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.3991 - accuracy: 0.9331 - val_loss: 0.5380 - val_accuracy: 0.8933\nEpoch 197/200\n1563/1563 [==============================] - 72s 46ms/step - loss: 0.3999 - accuracy: 0.9338 - val_loss: 0.5353 - val_accuracy: 0.8938\nEpoch 198/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.4002 - accuracy: 0.9319 - val_loss: 0.5357 - val_accuracy: 0.8942\nEpoch 199/200\n1563/1563 [==============================] - 71s 46ms/step - loss: 0.3997 - accuracy: 0.9329 - val_loss: 0.5353 - val_accuracy: 0.8940\nEpoch 200/200\n1563/1563 [==============================] - 71s 45ms/step - loss: 0.3966 - accuracy: 0.9335 - val_loss: 0.5315 - val_accuracy: 0.8947\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nepoch_nums = range(1, epochs+1)\ntraining_loss = h.history[\"loss\"]\nvalidation_loss = h.history[\"val_loss\"]\nplt.plot(epoch_nums , training_loss)\nplt.plot(epoch_nums , validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training','validation'], loc='upper right')\nplt.show()","execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"# Save the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = \"weights-ResNetImageClassificationAug.hdf5\"\nmodel.save_weights(fname,overwrite=True)","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fname = \"weights-ResNetImageClassificationAug.hdf5\"\nmodel.load_weights(fname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trained Model Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":35,"outputs":[{"output_type":"stream","text":"10000/10000 [==============================] - 3s 263us/step\nTest loss: 0.5315171558856964\nTest accuracy: 0.8946999907493591\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}